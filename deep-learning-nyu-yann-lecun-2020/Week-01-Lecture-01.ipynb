{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3dfb3d2",
   "metadata": {},
   "source": [
    "# Week 01 Lecture 01: History, Motivation, and Evolution of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124dc238",
   "metadata": {},
   "source": [
    "## History and Evolution of Deep Learning\n",
    "### 1940-1980s\n",
    "#### The idea of mimicking neurons in human brain started in 1940s (called Cybernetics then).\n",
    "#### Earlier experiments like Perceptron etc. used Binary Neurons. Binary Neurons never needed multiplication with weights. We had to simply add the weights for ON Neurons and discard weights corresponding to OFF neurons. Also, since floating point operations were feasible only in expensive computers till 1980s, Continuous Neurons (which are differentiable and hence we can apply Gradient Descent) were not at all considered a possibility till 1980s.\n",
    "#### Since we cannot do much other than some basic pattern recognition with proposed methods for Binary Neurons, interest in Cybernetics died out at the end of 1960s. Between end of 1960s to 1984, nobody was working in Neural Networks except some isolated researchers mostly in Japan.\n",
    "\n",
    "### 1985 - Backpropagation Algorithm\n",
    "#### By 1980s, floating point operations were feasible even for general purpose computers and the idea of using Continuous Neurons (i.e. Neurons using a Continuous Activiation Function) emerged. Backpropagation Algorithm can be used to perform Gradient Descent on such Continuous Neurons. This wave of interest in Neural Networks lasted about 10 years from 1985 to 1995 and died out again.\n",
    "\n",
    "### 2010 Onwards\n",
    "#### Around 2009 or 2010, people realized that Multilayer Neural Nets can be trained with Backprop and resulted in an improvement for Speech Recognition over traditional Hand-crafted methods. Within 2 years, almost every major player in Speech Recognition used Neural Nets and most of the Speech Recognition technology in Android phones used Neural Nets by 2012. That was the first world-wide deployment of modern forms of Deep Learning.\n",
    "#### Around the end of 2012 and early 2013, Computer Vision community realized that Deep Learning (Convolutional Nets in particular) works much better than traditional Computer Vision techniques that depended on Hand-crafted Features. That created a 2nd revolution in Computer Vision.\n",
    "#### Around 2015-2016, the same thing happened in Natural Language Processing.\n",
    "#### Now, we are going to see the same revolution in Robotics, Control and a whole bunch of application areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc0154",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "![Traditional Machine Learning Vs Deep Learning](images/week-01-lecture-01-image-01-traditional-ml-vs-deep-learning.png \"Traditional Machine Learning Vs Deep Learning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yann_env38",
   "language": "python",
   "name": "yann_env38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
